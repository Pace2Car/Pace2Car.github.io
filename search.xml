<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Springboot快速开发脚手架搭建]]></title>
    <url>%2F2019%2F10%2F23%2FSpringboot%E5%BF%AB%E9%80%9F%E5%BC%80%E5%8F%91%E8%84%9A%E6%89%8B%E6%9E%B6%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[项目详情springboot快速开发脚手架，集成Shiro、Mybatis-Plus、Redis、RabbitMQ、elastic-job、ShardingSphere、google retryer、可监控threadpool、二维码生成器、swagger2、log4j2等快速开发常用组件 项目已开源到Github-&gt;springbootquickstart 欢迎Clone、把玩 ~~]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用ShardingSphere分库分表]]></title>
    <url>%2F2019%2F10%2F23%2F%E4%BD%BF%E7%94%A8ShardingSphere%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[前言本文记录ShardingSphere的学习过程、使用心得 ，ShardingSphere是一套开源分布式数据库中间件解决方案组成的生态圈，前身是当当网开源的sharding-jdbc，捐给Apache孵化成为顶级项目后，更名为ShardingSphere。 学习资料直接参考官方文档，文档十分详细，可以完整的学习ShardingSphere各组件的基础概念及使用。 -&gt;ShardingSphere官方文档 后续文章将基于springboot搭建一个ShardingSphere Demo。 依赖创建一个Maven项目，引入spring的基本配置，在引入如下依赖123456789101112131415161718192021222324252627282930313233343536&lt;!-- sharding-jdbc --&gt;&lt;dependency&gt; &lt;groupId&gt;io.shardingsphere&lt;/groupId&gt; &lt;artifactId&gt;sharding-jdbc-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- mybatis-plus --&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;3.0.6&lt;/version&gt;&lt;/dependency&gt;&lt;!-- druid --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.10&lt;/version&gt;&lt;/dependency&gt;&lt;!-- pagehelper分页插件 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.5&lt;/version&gt;&lt;/dependency&gt;&lt;!-- mysql --&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.46&lt;/version&gt;&lt;/dependency&gt;&lt;!-- lombok --&gt;&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 配置spring 配置application.yml12345678910111213141516171819202122232425spring: profiles: active: sharding main: allow-bean-definition-overriding: true#mybatis-plus配置mybatis-plus: mapper-locations: classpath:com/pace2car/shardingspheredemo/dao/xml/*Mapper.xml typeAliasesPackage: cn.pace2car.shardingspheredemo.bean global-config: # 数据库相关配置 db-config: #主键类型 AUTO:&quot;数据库ID自增&quot;, INPUT:&quot;用户输入ID&quot;,ID_WORKER:&quot;全局唯一ID (数字类型唯一ID)&quot;, UUID:&quot;全局唯一ID UUID&quot;; id-type: auto #字段策略 IGNORED:&quot;忽略判断&quot;,NOT_NULL:&quot;非 NULL 判断&quot;),NOT_EMPTY:&quot;非空判断&quot; field-strategy: not_empty #驼峰下划线转换 table-underline: true #数据库大写下划线转换 capital-mode: false # 原生配置 configuration: map-underscore-to-camel-case: true cache-enabled: true sharding 策略配置application-sharding.yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849sharding: jdbc: datasource: names: ds0,ds1 ds0: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/demo_ds_0?useUnicode=true&amp;characterEncoding=UTF-8&amp;allowMultiQueries=true username: root password: 123456 ds1: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/demo_ds_1?useUnicode=true&amp;characterEncoding=UTF-8&amp;allowMultiQueries=true username: root password: 123456 config: sharding: # 默认指针列值生成器类类名称，缺省使用io.shardingsphere.core.keygen.DefaultKeyGenerator # 如果自定义实现io.shardingsphere.core.keygen.KeyGenerator接口并提供无参构造方法 #default-key-generator-class-name: com.pace2car.shardingspheredemo.keygenerator.MyKeyGenerator #executor: #size: 4 # 工作线程数量，默认是CPU核数的两倍 # 未配置分片规则的表将通过默认的数据源定位 default-data-source-name: ds0 # 数据库分片策略 default-database-strategy: inline: sharding-column: tenant_id algorithm-expression: ds$-&gt;&#123;tenant_id % 2&#125; # 默认的分表策略 #default-table-strategy: tables: tenant: actual-data-nodes: ds$-&gt;&#123;0..1&#125;.tenant park_record: actual-data-nodes: ds$-&gt;&#123;0..1&#125;.test_table_$-&gt;&#123;0..1&#125; table-strategy: inline: sharding-column: id algorithm-expression: test_table_$-&gt;&#123;id % 2&#125; key-generator-column-name: id #key-generator-class-name: com.pace2car.shardingspheredemo.keygenerator.MyKeyGenerator binding-tables: tenant,test_table props: sql: show: true # 显示sqlserver: port: 9090 启动类1234567891011121314151617181920package com.pace2car.shardingspheredemo;import org.mybatis.spring.annotation.MapperScan;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration;import org.springframework.context.annotation.ComponentScan;import org.springframework.transaction.annotation.EnableTransactionManagement;@SpringBootApplication(exclude = DataSourceAutoConfiguration.class)@ComponentScan(value = "com.pace2car")@MapperScan(basePackages = &#123;"com.pace2car.shardingspheredemo.dao.mapper"&#125;)@EnableTransactionManagement(proxyTargetClass = true)public class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 分表策略部署成功后，对大多数的业务并无影响，但是对涉及跨库join、复杂函数、多级不同结构的子查询等并不支持，相关的业务逻辑仍需调整。 源码涉及个人项目的敏感信息，目前在github设置了私有，希望查阅、交流的朋友可以在下方留言，我会抽时间整理一份脱敏代码开源。 后记分库分表是目前使用较多的，在很多维度都仍有遗留问题。于运维，分表的数据迁移和数据清洗，多库的DDL操作同步问题；于开发，分布式唯一主键的生成，分表后不能跨库join，业务流程也要考虑分布式事务的问题，同时还要保证分库分表策略能够支持扩容。 目前新兴的NewSQL可以很好的解决这些问题，也有很多优秀的开源产品，如TiDB、CockroachDB等。但是对生产来说，产品的成熟和稳定才是主要目的，并且这些DB的部署成本非常高，不适合业务规模并不庞大的中小公司。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>分库分表</tag>
        <tag>ShardingSphere</tag>
        <tag>ShardingJDBC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JAVA8新特性]]></title>
    <url>%2F2019%2F10%2F23%2FJAVA8%E6%96%B0%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[前言最近看了同事用lambda和stream写的代码，看起来着实优雅，读起来又有点费劲，便找资料学习了JAVA8的新特性，写此笔记，记录感悟。 新特性概览 速度更快 代码更少（增加了新的语法 Lambda 表达式） 强大的 Stream API 便于并行 最大化减少空指针异常 Optiona Lambda 表达式Lambda 表达式在Java 语言中引入了一个新的语法元素和操作符。这个操作符为 ==-&gt;== ， 该操作符被称为 Lambda 操作符或剪头操作符。它将 Lambda 分为两个部分： 左侧： 指定了 Lambda 表达式需要的所有参数 右侧： 指定了 Lambda 体，即 Lambda 表达式要执行的功能。 示例1： 无参无返回值12345678910// 匿名内部类实现Runnable r1 = new Runnable() &#123; @Override public void run() &#123; System.out.println("anno"); &#125;&#125;;// lambda表达式Runnable r2 = () -&gt; System.out.println("lambda"); 代码简洁度极大提升 示例2： 一个参数无返回值123456789Consumer&lt;String&gt; c1 = new Consumer&lt;String&gt;() &#123; @Override public void accept(String s) &#123; System.out.println(s); &#125;&#125;;常规：Consumer&lt;String&gt; c2 = (s) -&gt; System.out.println(s);单参数可省略小括号：Consumer&lt;String&gt; c2 = s -&gt; System.out.println(s); 示例3： 有返回值123456789101112BinaryOperator&lt;Long&gt; b1 = new BinaryOperator&lt;Long&gt;() &#123; @Override public Long apply(Long x, Long y) &#123; System.out.println("hello"); return x + y; &#125;&#125;;BinaryOperator&lt;Long&gt; b2 = (x, y) -&gt; &#123; System.out.println("hello"); return x + y;&#125;; 示例4： 当lambda体只有一句时，return和｛｝都可省略1234567891011BinaryOperator&lt;Long&gt; b1 = new BinaryOperator&lt;Long&gt;() &#123; @Override public Long apply(Long x, Long y) &#123; System.out.println("hello"); return x + y; &#125;&#125;;BinaryOperator&lt;Long&gt; b2 = (x, y) -&gt; x + y;等价于BinaryOperator&lt;Long&gt; b2 = (Long x, Long y) -&gt; x + y; lambda表达式中的参数类型可以通过 ==编译器类型推断== 得出，所以可以省略不写。 函数式接口 只包含一个抽象方法的接口，称为函数式接口。 你可以通过 Lambda 表达式来创建该接口的对象。（若 Lambda表达式抛出一个受检异常，那么该异常需要在目标接口的抽象方法上进行声明）。 我们可以在任意函数式接口上使用 ==@FunctionalInterface== 注解，这样做可以检查它是否是一个函数式接口，同时 javadoc 也会包含一条声明，说明这个接口是一个函数式接口。 方法引用当要传递给Lambda体的操作，已经有实现的方法了，可以使用方法引用！（实现抽象方法的参数列表，必须与方法引用方法的参数列表保持一致！ ） 方法引用： 使用操作符 ==::== 将方法名和对象或类的名字分隔开来。如下三种主要使用情况： 对象::实例方法 类::静态方法 类::实例方法 例如：1234567System.out::println 等价于(x) -&gt; System.out.println(x);s -&gt; "ss".equals(s)可写为"ss"::equals 代码简洁但可读性较低 Stream APIJava8中有两大最为重要的改变。第一个是 Lambda 表达式；另外一个则是 Stream API(java.util.stream.*)。 Stream 是 Java8 中处理集合的关键抽象概念，它可以指定你希望对集合进行的操作，可以执行非常复杂的查找、过滤和映射数据等操作。使用Stream API 对集合数据进行操作，就类似于使用 SQL 执行的数据库查询。也可以使用 Stream API 来并行执行操作。简而言之，Stream API 提供了一种高效且易于使用的处理数据的方式。 Stream（流）是什么是数据渠道，用于操作数据源（集合、数组等）所生成的元素序列。 集合讲的是数据，流讲的是计算！ 注意： Stream 自己不会存储元素。 Stream 不会改变源对象。相反，他们会返回一个持有结果的新Stream。 Stream 操作是延迟执行的。这意味着他们会等到需要结果的时候才执行。 如何使用Stream 的操作三个步骤： 创建 Stream 一个数据源（如： 集合、数组）， 获取一个流12345678910111213集合：Java8 中的 Collection 接口被扩展，提供了两个获取流的方法：- default Stream&lt;E&gt; stream() : 返回一个顺序流- default Stream&lt;E&gt; parallelStream() : 返回一个并行流Java8 中的 Arrays 的静态方法 stream() 可以获取数组流：- static &lt;T&gt; Stream&lt;T&gt; stream(T[] array): 返回一个流重载形式，能够处理对应基本类型的数组：- public static IntStream stream(int[] array)- public static LongStream stream(long[] array)- public static DoubleStream stream(double[] array) 中间操作 一个中间操作链，对数据源的数据进行处理12345678中间层进行了具体的数据操作，常见有：filter(Predicate p) 接收lambda,筛选distinct() 去重limit(long size) 截断skip(long number) 跳过（与截断互补）map(Function f) 接收函数，作用到每个元素并映射为新元素sorted()/sorted(Comparator c) 自然排序/按规则排序 终止操作(终端操作) 一个终止操作，执行中间操作链，并产生结果 以常用的集合操作为例：123456789101112131415161718192021222324252627282930313233public class StreamDemo &#123; public static void main(String[] args) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); list.add("s1"); list.add("s2"); list.add("s3"); list.add("s4"); list.add("s5"); List&lt;String&gt; collect = list.stream().filter(s -&gt; "s1".equals(s)).collect(Collectors.toList()); collect.forEach(System.out::println); &#125;&#125;执行打印结果中就只有 "s1" 了终止操作最常用的是返回集合collect(Collector c)，并且Collectors提供了很多静态方法，可以满足不同需求另外还提供一些接口：---查找findFirst() 返回第一个元素findAny() 返回任意一个元素count() 返回总数max(Comparator c) 按规则返回最大值min(Comparator c) 按规则返回最小值forEach(Consumer c) 内部迭代（集合的迭代叫外部迭代）---匹配allMatch(Predicate p) 全匹配anyMatch(Predicate p) 任意一个匹配noneMatch(Predicate p) 全不匹配---归约reduce(BinaryOpreator b) 反复结合得到一个值, 返回Optional&lt;T&gt;reduce(T iden, BinaryOpreator b) 反复结合得到一个值, 返回T stream还有很多强大的功能，可以写个demo自行测试，api文档里也描述得非常全面。java8中文文档 并行流与串行流并行流就是把一个内容分成多个数据块，并用不同的线程分别处理每个数据块的流。Java 8 中将并行进行了优化，我们可以很容易的对数据进行并行操作。 Stream API 可以声明性地通过 ==parallel()== 与==sequential()== 在并行流与顺序流之间进行切换。 fork/join （了解）Fork/Join 框架：就是在必要的情况下，将一个大任务，进行拆分(fork)成若干个小任务（拆到不可再拆时），再将一个个的小任务运算的结果进行 join 汇总。 新的时间API LocalDate LocalTime LocalDateTime Instant Duration Period 解决了时间处理的难题 简单概括为Date有的我都有，Date没的我也有 时间校正器 TemporalAdjuster：校正器，获取“下个周日”等操作 TemporalAdjusters：通过静态方法提供大量常用校正实实现 示例代码：12345678910public class LocalDateTimeDemo &#123; public static void main(String[] args) &#123; LocalDateTime now = LocalDateTime.now(); System.out.println(now.getDayOfWeek()); System.out.println(now.getDayOfYear()); LocalDateTime with = now.with(TemporalAdjusters.next(DayOfWeek.TUESDAY)); System.out.println(with.getDayOfWeek()); System.out.println(with.getDayOfYear()); &#125;&#125; 解析与格式化java.time.format.DateTimeFormatter 类：该类提供了三种格式化方法： 预定义的标准格式 语言环境相关的格式 自定义的格式 接口可以有默认实现和静态方法示例123456789101112131415161718192021public interface DefaultAndStaticDemo &#123; /** * 常规方法定义 */ void method(); /** * 默认方法 * @return */ default String sayHi() &#123; return "Hi default!"; &#125; /** * 静态方法 */ static void sayHello() &#123; System.out.println("Hello static!"); &#125;&#125; 接口方法有默认实现后，就带来了必不可少的方法冲突问题，主要为以下两大类： 继承的父类与实现的接口冲突：采用 ==类优先法则== ，即优先使用类中的方法实现，忽略接口的默认实现 接口冲突：如果一个父接口提供一个默认方法，而另一个接口也提供了一个具有相同名称和参数列表的方法（不管方法是否是默认方法），那么必须重写该方法来解决冲突 后记JAVA8中最主要的特点还是lambda表达式和stream API，功能强大且代码简洁，与JAVA一直以来被诟病代码格式刻板（个人觉得还是简单易读就好）有了一定的改善，总结来看只怪自己学习太晚，整天研究解决方案，连基本的语言基础都落下了。 JAVA8后的首个长期支持版本JAVA11已经于去年发布，目前不少团队已经将JAVA11投入生产了，当然主流版本仍然是JAVA8（1.稳定；2.JAVA8确实够用了）。 另外JAVA14也预计在2020年3月发布，作为JAVA程序员真的好方…]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[J.U.C学习笔记]]></title>
    <url>%2F2019%2F01%2F08%2FJ.U.C%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[引言合理利用线程池能够带来三个好处。 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不需要的等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 但是要做到合理的利用线程池，必须对其原理了如指掌。 多线程编程基础 Java基础 线程基本概念 创建线程的方式 实现同步锁的方式 参考书籍：《Java并发编程核心技术》-&gt;基础、《Java并发编程实战》 J.U.C基本概念及源码解析J.U.C基础 深入理解Java线程池：ThreadPoolExecutor 创建使用ThreadPoolExecutor虽然Javadocs推荐我们使用Executors利用工厂模式向我们提供的4种线程池实现方式，但是在阿里编码规约里并不推荐使用，原因是使用Executors创建线程池不会传入这个参数而使用默认值所以我们常常忽略这一参数，而且默认使用的参数会导致资源浪费，不可取。 【强制】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式， 这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 ExecutorTest.Java12345678910111213141516171819202122232425262728package com.pace2car;import java.util.concurrent.*;/** * @author Pace2Car * @date 2019/1/8 15:21 */public class ExecutorTest &#123; public static void main(String[] args) throws InterruptedException &#123; ThreadFactory namedThreadFactory = Executors.defaultThreadFactory(); ThreadPoolExecutor executor = new ThreadPoolExecutor(2, 5, 200, TimeUnit.MILLISECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(5), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy()); for (int i = 0; i &lt; 10; i++) &#123; MyTask myTask = new MyTask(i); executor.execute(myTask); System.out.println("线程池中线程数目："+executor.getPoolSize()+"，队列中等待执行的任务数目："+ executor.getQueue().size()+"，已执行完毕的任务数目："+executor.getCompletedTaskCount()); &#125; executor.shutdown(); Thread.sleep(5000); System.out.println("线程池中线程数目："+executor.getPoolSize()+"，队列中等待执行的任务数目："+ executor.getQueue().size()+"，已执行完毕的任务数目："+executor.getCompletedTaskCount()); &#125;&#125; MyTask.Java123456789101112131415161718192021222324package com.pace2car;/** * @author Pace2Car * @date 2019/1/8 15:27 */public class MyTask implements Runnable &#123; private int taskNum; public MyTask(int num) &#123; this.taskNum = num; &#125; @Override public void run() &#123; System.out.println("正在执行task "+taskNum); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("task "+taskNum+"执行完毕"); &#125;&#125;]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>Thread</tag>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式学习笔记]]></title>
    <url>%2F2019%2F01%2F02%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[设计模式学习笔记此笔记为《大话设计模式》一书学习总结 菜鸟学习资料 参考代码篇幅比较长，所以没有放到文章中→参考代码 分类java的设计模式大体上分为三大类： 创建型模式（5种）：工厂方法模式、抽象工厂模式、单例模式、建造者模式、原型模式。 结构型模式（7种）：适配器模式、装饰器模式、代理模式、外观模式、桥接模式、组合模式、享元模式。 行为型模式（11种）：策略模式、模板方法模式、观察者模式、迭代子模式、责任链模式、命令模式、备忘录模式、状态模式、访问者模式、中介者模式、解释器模式。 设计原则设计模式遵循的原则有6个： 1、单一职责原则（Single Responsibility Principle） 应该有且仅有一个原因引起类的变更。 2、里氏代换原则（Liskov Substitution Principle） 只有当衍生类可以替换掉基类，软件单位的功能不受到影响时，基类才能真正被复用，而衍生类也能够在基类的基础上增加新的行为。 3、依赖倒转原则（Dependence Inversion Principle） 这个是开闭原则的基础，对接口编程，依赖于抽象而不依赖于具体。 4、接口隔离原则（Interface Segregation Principle） 使用多个隔离的借口来降低耦合度。 5、迪米特法则（最少知道原则）（Demeter Principle） 一个实体应当尽量少的与其他实体之间发生相互作用，使得系统功能模块相对独立。 6、开闭原则（Open Close Principle） 对扩展开放，对修改关闭。 简单工厂模式（非正式模式、热身）用一个单独的类来做创造实例的工作 策略模式定义算法家族，分别封装起来，让它们之间可以互相替换。使算法的变化，不会影响到使用算法的用户 利用Context对象来封装算法的变化，使用户可以无感知的切换算法。虽然并没完全消除系统选择算法的压力，但是策略与工厂结合后，可以让Context来承担这一任务，最大化的减轻用户的职责 单一职责原则就一个类而言，应该仅有一个引起它变化的原因。 软件设计真正要做的许多内容，就是发现职责并把那些职责相互分离 判断一个类是否应该分离出类来，就是去判断是否有多于一个动机去改变一个类，也就是说，这个类是否仅有一个职责 开放-封闭原则（Open-Closeed Principle）不能修改原有的，但可以扩展新来的 对于扩展是开放的，对于更改是封闭的。 Open for extension,Closed for modification. 依赖倒转原则（Dependence Inversion Principle）简单来说就是针对接口编程，而不要针对实现编程 1.高层模块不应该依赖地层模块，两者都应该依赖抽象。 2.抽象不应该依赖细节，细节应该依赖于抽象。 里氏代换原则（Liskov Substitution Principle）一个软件实体如果使用的是一个父类的话，那么一定适用于其子类，而且它察觉不出父类与子累的区别。也就是说，在软件里面，把父类都替换成它的子类，程序的行为是没有任何变化的 子类必须能够替换掉它们的父类 装饰模式（Decorator Pattern）也称油漆工模式，把所需要的功能按正确的顺序串联起来进行控制 动态地给一个对象添加一些额外的职责，就增加功能来说，装饰模式比生成子类更为灵活。 为已有的功能动态地添加更多的功能 当系统需要新功能的时候，如果通过新加代码来增添功能，会增加主类的复杂度，此时通过装饰模式，将要装饰的功能放在单独的类中，并让这个类包装它要装饰的对象，这样在执行时，客户端就可以在运行时有选择，按顺序的使用装饰功能来包装对象。这样的设计可以有效的将类的核心职责和装饰功能区分开来，而且可以去除相关类中的重复装饰逻辑。 所以，大胆的去裸奔吧，穿衣服的事就交给装饰器来做 代理模式（Proxy Pattern）找个跑腿的帮你办事，使办事对象不能直接接触到你 为其他对象提供一种代理以控制对某个对象的访问。 常见的实现远程调用、aop等 工厂方法模式（Factory Method Pattern）工厂方法是在简单工厂上的提升，更加符合开-闭原则 定义一个用于创建对象的接口，让子类来决定实例化哪一个类。工厂方法使一个类的实例化延迟到其子类。 原型模式（Prototype Pattern）从一个对象再创建另一个可定制的对象，而且不需要知道任何创建的细节 用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。 浅复制与深复制浅复制： 对值类型复制其值，对引用类型复制其引用。 深复制： 在浅复制的基础上，把引用对象的变量指向复制过的新对象，而不是原有的被引用对象。 模版方法模式（Template Pattern）当我们要完成在某一细节层次一致的一个过程或一系列步骤，但其个别步骤在更详细的层次上的实现可能不同时，我们通常考虑用模版方法模式来处理 定义一个操作中的算法的骨架，而将一些步骤延迟到子类中。 模版方法使得子类可以不改变一个算法的结构即可重定义该算法的某些特定步骤。 通过把不变的行为搬移到超类，去除子类中的重复代码来提供一个代码复用平台 迪米特法则也叫最少知识原则 如果两个类不必彼此直接通信，那么这两个类就不应当发生直接的相互作用。 如果其中一个类需要调用另一个类的某一个方法的话，可以通过第三者转发这个调用。 在面向对象的程序设计中，累之间的耦合越弱，越有利于复用 外观模式（Facade Pattern）为子系统中的一组接口提供一个一致的界面，此模式定义了一个高层接口，这个接口使得这一子系统更加容易使用。 建造者模式（Builder Pattern）当创建复杂对象的算法应该独立于该对象的组成部分以及它们的装配方法时适用 将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示。 用户只需要指定需要建造的类型，而不需要知道建造的过程和细节。 观察者模式（Observer Pattern）又叫 发布/订阅模式(Pub/Sub) 定义了一种多对多的关系，让多个观察者对象同时监听某一个主题对象（抽象通知者）。 这个主题对象在状态发生变化时，会通知所有观察者对象，使它们能够自动更新自己。 这样的实现仍然会有抽象依赖的问题，因此我们可以应用委托技术来解决这一问题 java中没有像c#中delegate这样的概念，因此还得自己靠反射实现 通过委托，可以完全解耦通知者与观察者，观察者之间也不需要有任何联系 抽象工厂模式（Abstract Factory Pattern）提供一个创建一系列相关或相互依赖对象的接口，而无需指定它们具体的类。 纯粹的抽象工厂模式还存在许多的缺陷，比如需求改变时的工作量将会是巨大的。 因此，我们考虑用一种更灵活的方式来实现实例的创建： 依赖注入（Dependency Injection），没错，就是Spring的IoC。 当然，底层实现也是利用反射来实现的，配合配置文件的使用，以达到灵活控制的效果 状态模式（State Pattern）当一个对象的内在状态改变时允许改变其行为，这个对象看起来像是改变了其类。 状态模式主要解决的是当控制一个对象状态转换的条件表达式过于复杂时的情况。把状态的判断逻辑转移到表示不同状态的一系列类当中，可以把复杂的判断逻辑简化。 不过这样写的代码耦合比较严重，建议少用 适配器模式（Adapter Pattern）将一个类的接口转换成客户希望的另外一接口。 Adapter模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。 当系统的数据和行为都正确，但接口不符时，我们应该考虑使用适配器，目的是使控制范围之外的一个原有对象与某个接口匹配。 适配器模式主要应用于希望复用一些现存的类，但是借口又与复用环境要求不一致的情况。 在GoF的设计模式中，适配器分两种类型：类适配器和对象适配器。 由于类适配器通过多继承进行匹配（C++支持Java不支持），所以主要学习对象适配器。 在实际开发中应尽可能早的去重构代码来解决接口的适配问题，不要堆到最后用适配器来解决，这样的代码是不健康的。 备忘录模式（Memento Pattern）在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态。 这样以后就可以将该对象恢复到原先保存的状态。 将对象的一些内部信息保存在对象以外的地方，但必须要求由对象自己读取 组合模式（Composite Pattern）当发现需求是体现部分与整体层次的结构时，当开发者希望用户可以忽略组合对象与单个对象的不同，统一的使用组合结构中的所有对象时。 将对象组合成树形结构以表示“部分-整体”的层次结构。 组合模式使得用户对单个对象和组合对象的使用具有一致性。 透明方式：在Component中声明add和remove方法，是树枝和叶子对外接口保持一致，但叶子是不具备add和remove功能的,叶子实现他没有意义。 安全方式：在Component中不去声明add和remove，只在Composite中声明，这样Leaf类便不会知道add和remove方法，但这样做不够透明，客户端在调用时需要做出相应的判断。 迭代器模式（Iterator Pattern）提供一种方法顺序访问一个聚合对象中各个元素，而又不暴露该对象的内部表示。 典型例子： Java中的Iterator 当访问哦一个聚集对象，且不管这些对象是什么都需要遍历的时候，或者对聚集有多种遍历方式的时候，需要用到迭代器模式。不过现在的高级语言都已经把这个模式做在语言中了（foreach），所以自己实现的场景非常的少。 单例模式（Singleton Pattern）软件中的计划生育 保证一个类仅有一个实例，并提供一个访问它的全局访问点。 桥接模式（Bridge Pattern）将抽象部分与他的实现部分分离，使它们都可以独立地变化。 简单来说，实现系统可能有多角度分类，每一种分类都有可能变化，那么就把这种多角度分离出来让它们独立变化，减少它们之间的耦合 合成/聚合复用原则（CARP）尽量使用合成/聚合，尽量不要使用类继承。 优先使用对象的合成/聚合将有助于你保持每个类被封装，并被集中在单个任务上 这样类和类继承层次会保持较小规模，并且不太可能增长为不可控制的庞然大物。 命令模式（Command Pattern）将一个请求封装为一个对象，从而使你可用不同的请求对客户进行参数化，对请求排队或记录请求日志，以及支持可撤销的操作。 职责链模式（Chain of Responsibility Pattern）使多个对象都有机会处理请求，从而避免请求的发送者和接收者之间的耦合关系。 将这个对象连成一条链，并沿着这条链传递该请求，直到有一个对象处理它为止。 接受者和发送者都没有对方的明确信息，且链中的对象自己也并不知道链的结构。结果是职责链可简化对象的相互连接，它们仅需保持一个指向其后继者的引用，而不需保持它所有的候选接受者的引用。用户可以随时增加或修改请求的处理结构，大大增加了灵活性，降低了耦合度。 中介者模式（Mediator Pattern）用一个中介对象来封装一系列的对象交互。 中介者使各对象不需要显式地相互引用，从而使其耦合松散，而且可以独立地改变它们之间的交互。 可以减少各个通信对象间的耦合，但如果系统出现“多对多”的复杂交互对象时，应谨慎考虑使用中介者模式。 享元模式（Flyweight Pattern）运用共享技术有效的支持大细粒度的对象。 当一个程序使用了大量的对象，而这些对象造成了很大的存储开销时，应当考虑使用享元模式 解释器模式（Interpreter Pattern）如果一种特定类型的问题发生的频率足够搞那么可能就是值得将该问题的各个实例表述为一个简单语句中的句子。这样就可以构建一个解释器，该解释器通过解释这些句子来解决该问题。 给定一个语言，定义它的文法的一种表示，并定义一个解释器，这个解释器使用该表示来解释语言中的句子。 当有一个语言需要解释执行，并且你可将该语言中的句子表示为一个抽象语法树时，可使用解释器模式 注：可利用场景比较少，JAVA 中如果碰到可以用 expression4J 代替。 访问者模式（Visitor Pattern）这个算是GoF提出的最复杂的设计模式了 表示一个作用于某对象结构中的各元素的操作。 它使你可以在不改变各元素的类的前提下定义作用于这些元素的新操作。 访问者模式适用于数据结构相对稳定的系统 小结通过这段时间对设计模式的学习，我算是对我的面向对象编程思想做了个思维大体操，回头看看以前自己闷着头只为实现功能写的代码，真是不堪直视。突然发现，到现在为止，我的java编程才算入了门。以后写代码的时候多少也会考虑一下是否完全遵循了六大原则。 要说立马就能去合理应用这些设计模式还是不现实的，在今后的设计中，随时带着设计模式的思维来思考，一步一步的将这些东西融汇到思想中，做到并不知道自己用了什么模式才算真正学会了！ 后来的补充随着技术的发展与演进，人们又提出了许多的补充模式，以适应现代企业的开发需求。 这些模式在现代开发就非常的常见了 MVC模式（Model-View-Controller Pattern）这种模式用于应用程序的分层开发。 数据传输对象模式（Transfer Object Pattern）传输对象是一个具有 getter/setter 方法的简单的 POJO 类，它是可序列化的，所以它可以通过网络传输 数据访问对象模式（Data Access Object Pattern）DAO 模式用于把低级的数据访问 API 或操作从高级的业务服务中分离出来。 前端控制器模式（Front Controller Pattern）用来提供一个集中的请求处理机制，所有的请求都将由一个单一的处理程序处理。 该处理程序可以做认证/授权/记录日志，或者跟踪请求，然后把请求传给相应的处理程序。 业务代表模式（Business Delegate Pattern）用于对表示层和业务层解耦。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>面向对象</tag>
        <tag>编程思想</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[0.SpringCloud起步]]></title>
    <url>%2F2018%2F12%2F29%2F0-SpringCloud%E8%B5%B7%E6%AD%A5%2F</url>
    <content type="text"><![CDATA[什么是SpringCloud微服务架构集大成者，云计算最佳业务实践。 Spring Cloud为开发人员提供了快速构建分布式系统中一些常见模式的工具（例如配置管理，服务发现，断路器，智能路由，微代理，控制总线）。分布式系统的协调导致了样板模式, 使用Spring Cloud开发人员可以快速地支持实现这些模式的服务和应用程序。他们将在任何分布式环境中运行良好，包括开发人员自己的笔记本电脑，裸机数据中心，以及Cloud Foundry等托管平台。 主要技术栈 程序流程 主要学习资料史上最简单的SpringCloud教程]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
        <tag>微服务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis学习笔记]]></title>
    <url>%2F2018%2F12%2F21%2FRedis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基本概念（搬运）REmote DIctionary Server(Redis) 是一个由Salvatore Sanfilippo写的key-value存储系统。 Redis是一个开源的使用ANSIC语言编写、遵守BSD协议、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。 它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Map), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。 入门Redis的安装与配置Windows下载地址 直接解压进入，当前位置打开cmd1redis-server.exe redis.windows.conf 看见如下界面，启动成功 访问redis需要另起一个cmd窗口，前面的服务窗口不要关闭123456789redis-cli.exe (-h 127.0.0.1 -p 6379)括号内可以省略127.0.0.1:6379&gt; set yourKey yourValue127.0.0.1:6379&gt; get yourKey此时默认使用的是string的数据结构所以得到返回值127.0.0.1:6379&gt; &quot;yourValue&quot; Redis的数据结构Redis支持五种数据类型：string（字符串），hash（哈希），list（列表），set（集合）及zset(sorted set：有序集合)。 在Java应用中使用RedisJedis实现 参考项目：Redis在Java应用中的测试 SpringMVC+Mybatis整合Redis做二级缓存第一步当然是引入依赖包123456789101112131415&lt;!-- Redis --&gt;&lt;properties&gt; &lt;jedis.version&gt;2.9.0&lt;/jedis.version&gt;&lt;/properties&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;$&#123;jedis.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-redis&lt;/artifactId&gt; &lt;version&gt;1.8.6.RELEASE&lt;/version&gt;&lt;/dependency&gt; 接下来需要创建几个Redis的Util类SerializeUtil.Java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147package com.pace2car.redis;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.io.*;import java.util.ArrayList;import java.util.List;/** * 序列化与反序列化Util类（实体类必须实现序列化接口） * @author Pace2Car * @date 2018/12/21 10:08 */public class SerializeUtil &#123; private static Logger log = LoggerFactory.getLogger(SerializeUtil.class); public static byte[] serialize(Object object) &#123; ObjectOutputStream oos = null; ByteArrayOutputStream baos = null; byte[] bytes = null; try &#123; // 序列化 baos = new ByteArrayOutputStream(); oos = new ObjectOutputStream(baos); oos.writeObject(object); bytes = baos.toByteArray(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; if (oos != null) &#123; oos.close(); &#125; if (baos != null) &#123; baos.close(); &#125; &#125; catch (Exception e2) &#123; e2.printStackTrace(); &#125; &#125; return bytes; &#125; /** * 反序列化对象 * @param bytes * @return */ public static Object unserialize(byte[] bytes) &#123; Object obj = null; ByteArrayInputStream bais = null; try &#123; // 反序列化 bais = new ByteArrayInputStream(bytes); ObjectInputStream ois = new ObjectInputStream(bais); obj = ois.readObject(); ois.close(); bais.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return obj; &#125; /** * 关闭的数据源或目标。调用 close()方法可释放对象保存的资源（如打开文件） * 关闭此流并释放与此流关联的所有系统资源。如果已经关闭该流，则调用此方法无效。 * @param closeable */ public static void close(Closeable closeable) &#123; if (closeable != null) &#123; try &#123; closeable.close(); &#125; catch (Exception e) &#123; log.info("Unable to close %s", closeable, e); &#125; &#125; &#125; /** * 列表序列化（用于Redis整存整取） * @param value * @return */ public static &lt;T&gt; byte[] serialize(List&lt;T&gt; value) &#123; if (value == null) &#123; throw new NullPointerException("Can't serialize null"); &#125; byte[] rv=null; ByteArrayOutputStream bos = null; ObjectOutputStream os = null; try &#123; bos = new ByteArrayOutputStream(); os = new ObjectOutputStream(bos); for(T obj : value)&#123; os.writeObject(obj); &#125; os.writeObject(null); os.close(); bos.close(); rv = bos.toByteArray(); &#125; catch (IOException e) &#123; throw new IllegalArgumentException("Non-serializable object", e); &#125; finally &#123; close(os); close(bos); &#125; return rv; &#125; /** * 反序列化列表（用于Redis整存整取） * @param in * @return */ public static &lt;T&gt; List&lt;T&gt; unserializeForList(byte[] in) &#123; List&lt;T&gt; list = new ArrayList&lt;T&gt;(); ByteArrayInputStream bis = null; ObjectInputStream is = null; try &#123; if(in != null) &#123; bis=new ByteArrayInputStream(in); is=new ObjectInputStream(bis); while (true) &#123; T obj = (T) is.readObject(); if(obj == null)&#123; break; &#125;else&#123; list.add(obj); &#125; &#125; is.close(); bis.close(); &#125; &#125; catch (IOException e) &#123; log.warn("Caught IOException decoding %d bytes of data", in == null ? 0 : in.length, e); &#125; catch (ClassNotFoundException e) &#123; log.warn("Caught CNFE decoding %d bytes of data", in == null ? 0 : in.length, e); &#125; finally &#123; close(is); close(bis); &#125; return list; &#125;&#125; RedisCacheTransfer.Java12345678910111213141516package com.pace2car.redis;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.connection.jedis.JedisConnectionFactory;/** * 完成RedisCache.jedisConnectionFactory的静态注入 * @author Pace2Car * @date 2018/12/21 10:06 */public class RedisCacheTransfer &#123; @Autowired public void setJedisConnectionFactory(JedisConnectionFactory jedisConnectionFactory) &#123; RedisCache.setJedisConnectionFactory(jedisConnectionFactory); &#125;&#125; RedisCache.Java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145package com.pace2car.redis;import org.apache.ibatis.cache.Cache;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.data.redis.connection.jedis.JedisConnection;import org.springframework.data.redis.connection.jedis.JedisConnectionFactory;import org.springframework.data.redis.serializer.JdkSerializationRedisSerializer;import org.springframework.data.redis.serializer.RedisSerializer;import redis.clients.jedis.exceptions.JedisConnectionException;import java.util.concurrent.locks.ReadWriteLock;import java.util.concurrent.locks.ReentrantReadWriteLock;/** * 缓存实现类 * @author Pace2Car * @date 2018/12/21 10:11 */public class RedisCache implements Cache &#123; private static final Logger logger = LoggerFactory.getLogger(RedisCache.class); private static JedisConnectionFactory jedisConnectionFactory; private final String id; /** * The &#123;@code ReadWriteLock&#125;. */ private final ReadWriteLock readWriteLock = new ReentrantReadWriteLock(); public RedisCache(final String id) &#123; if (id == null) &#123; throw new IllegalArgumentException("Cache instances require an ID"); &#125; logger.debug("MybatisRedisCache:id=" + id); this.id = id; &#125; @Override public void clear() &#123; JedisConnection connection = null; try &#123; //连接清除数据 connection = (JedisConnection) jedisConnectionFactory.getConnection(); connection.flushDb(); connection.flushAll(); &#125; catch (JedisConnectionException e) &#123; e.printStackTrace(); &#125; finally &#123; if (connection != null) &#123; connection.close(); &#125; &#125; &#125; @Override public String getId() &#123; return this.id; &#125; @Override public Object getObject(Object key) &#123; Object result = null; JedisConnection connection = null; try &#123; connection = (JedisConnection) jedisConnectionFactory.getConnection(); //借用spring_data_redis.jar中的JdkSerializationRedisSerializer.class RedisSerializer&lt;Object&gt; serializer = new JdkSerializationRedisSerializer(); //利用其反序列化方法获取值 result = serializer.deserialize(connection.get(serializer.serialize(key))); &#125; catch (JedisConnectionException e) &#123; e.printStackTrace(); &#125; finally &#123; if (connection != null) &#123; connection.close(); &#125; &#125; return result; &#125; @Override public ReadWriteLock getReadWriteLock() &#123; return this.readWriteLock; &#125; @Override public int getSize() &#123; int result = 0; JedisConnection connection = null; try &#123; connection = (JedisConnection) jedisConnectionFactory.getConnection(); result = Integer.valueOf(connection.dbSize().toString()); &#125; catch (JedisConnectionException e) &#123; e.printStackTrace(); &#125; finally &#123; if (connection != null) &#123; connection.close(); &#125; &#125; return result; &#125; @Override public void putObject(Object key, Object value) &#123; JedisConnection connection = null; try &#123; logger.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;putObject:" + key + "=" + value); connection = (JedisConnection) jedisConnectionFactory.getConnection(); //借用spring_data_redis.jar中的JdkSerializationRedisSerializer.class RedisSerializer&lt;Object&gt; serializer = new JdkSerializationRedisSerializer(); //利用其序列化方法将数据写入redis服务的缓存中 connection.set(serializer.serialize(key), serializer.serialize(value)); &#125; catch (JedisConnectionException e) &#123; e.printStackTrace(); &#125; finally &#123; if (connection != null) &#123; connection.close(); &#125; &#125; &#125; @Override public Object removeObject(Object key) &#123; JedisConnection connection = null; Object result = null; try &#123; connection = (JedisConnection) jedisConnectionFactory.getConnection(); RedisSerializer&lt;Object&gt; serializer = new JdkSerializationRedisSerializer(); result = connection.expire(serializer.serialize(key), 0); &#125; catch (JedisConnectionException e) &#123; e.printStackTrace(); &#125; finally &#123; if (connection != null) &#123; connection.close(); &#125; &#125; return result; &#125; public static void setJedisConnectionFactory(JedisConnectionFactory jedisConnectionFactory) &#123; RedisCache.jedisConnectionFactory = jedisConnectionFactory; &#125;&#125; 配置完成后需要在mybatis配置中添加缓存支持1234567891011&lt;!--设置mybaits对redis缓存的支持--&gt;&lt;property name=&quot;configurationProperties&quot;&gt; &lt;props&gt; &lt;!-- 全局映射器启用缓存 *主要将此属性设置完成即可--&gt; &lt;prop key=&quot;cacheEnabled&quot;&gt;true&lt;/prop&gt; &lt;!-- 查询时，关闭关联对象即时加载以提高性能 --&gt; &lt;prop key=&quot;lazyLoadingEnabled&quot;&gt;false&lt;/prop&gt; &lt;!-- 设置关联对象加载的形态，此处为按需加载字段(加载字段由SQL指 定)，不会加载关联表的所有字段，以提高性能 --&gt; &lt;prop key=&quot;aggressiveLazyLoading&quot;&gt;true&lt;/prop&gt; &lt;/props&gt;&lt;/property&gt; 使用缓存使用时需在mapper.xml中开启缓存12345&lt;!-- LRU垃圾数据清理算法，默认为LRU 最近最少使用 --&gt;&lt;cache eviction=&quot;LRU&quot; type=&quot;com.pace2car.redis.RedisCache&quot; /&gt;&lt;!-- 在语句上开启 useCache=&quot;true&quot; --&gt;&lt;select id=&quot;selectByPrimaryKey&quot; resultMap=&quot;BaseResultMap&quot; parameterType=&quot;java.lang.Integer&quot; useCache=&quot;true&quot; &gt; 写测试类测试查询后，在redis客户端看见有新的key添加进来 实体类加上serialVersionUIDserialVersionUID适用于Java的序列化机制。简单来说，Java的序列化机制是通过判断类的serialVersionUID来验证版本一致性的。在进行反序列化时，JVM会把传来的字节流中的serialVersionUID与本地相应实体类的serialVersionUID进行比较，如果相同就认为是一致的，可以进行反序列化，否则就会出现序列化版本不一致的异常，即是InvalidCastException。 1private static final long serialVersionUID = 3404843471959911386L; 至此Redis便可作为二级缓存使用啦，后续会放上Redis集群的配置，进一步提高系统的性能。参考项目： Redis做二级缓存参考项目]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>jedis</tag>
        <tag>二级缓存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shiro学习笔记]]></title>
    <url>%2F2018%2F12%2F18%2FShiro%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本文由此文的学习总结，完整学习参考此文 基本概念一般涉及到用户参与的系统，都会涉及权限管理，权限管理属于系统安全的问题，实现对用户访问的控制，限制用户的访问。 权限管理主要包括两个部分：身份验证和授权 入门一句话：Apache Shiro 是Java语言开发的一个安全框架。学习Shiro首要了解他的核心结构 SecurityManager为核心认证/权限管理 在java中初步使用Shiro创建一个quickstart的maven项目 引入依赖12345&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-core&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt;&lt;/dependency&gt; 创建一个ini配置来模拟用户数据shiro.ini123[users]#模拟用户 username=passwordpace2car=123456 创建测试类12345678910111213141516171819202122232425262728public class ShiroTest &#123; private final static Log logger = LogFactory.getLog(ShiroTest.class); @Test public void testLogin() &#123; //加载配置 创建工厂 Factory&lt;SecurityManager&gt; factory = new IniSecurityManagerFactory("classpath:shiro.ini"); //创建实例 SecurityManager securityManager = factory.getInstance(); //绑定到运行环境中 SecurityUtils.setSecurityManager(securityManager); //创建登录主体 Subject subject = SecurityUtils.getSubject(); //绑定主体的身份和凭证 UsernamePasswordToken token = new UsernamePasswordToken("pace2car", "123456"); //主体登录 subject.login(token); //验证登录 logger.info("用户登录状态:" + subject.isAuthenticated());//true //登出 subject.logout(); logger.info("用户登录状态:" + subject.isAuthenticated());//false &#125;&#125; 一般情况下，认证失败会有一下两种异常： 用户名不存在异常 1UnknownAccountException 密码错误异常 1IncorrectCredentialsException 我们可以catch这两种异常的来做出响应 自定义Realm根据上面提到的demo，通过对其登录操作的流程分析，不难发现仍有许多的遗留问题 通过自定义Realm,重写其中的方法，使其更能适应实际需求 一般来说我们继承AuthorizingRealm类（通过Realm的继承树可以看出，这个类包含类基本的认证和授权），并重写其中的方法 123456789101112131415161718192021222324252627282930313233343536373839404142public class MyRealm extends AuthorizingRealm &#123; @Override public String getName() &#123; return "myRealm"; &#125; /** * 授权 * @param principals * @return */ @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) &#123; return null; &#125; /** * 认证 * @param token 登录信息包装成的信息 * @return * @throws AuthenticationException */ @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; System.out.println(token); //获取登录的用户名 String username = (String) token.getPrincipal(); //通过用户名到数据库中去查，返回User对象方便比较 //假设已返回数据 if (!"pace2car".equals(username)) &#123; return null; &#125; String password = "123456"; //info对象表示realm登录比对信息 SimpleAuthenticationInfo info = new SimpleAuthenticationInfo(username, password, getName()); return info; &#125;&#125; MD5密码加密123456789101112131415161718192021public class MD5Test &#123; private final static Log logger = LogFactory.getLog(MD5Test.class); @Test public void testMD5() &#123; String password = "123456"; //加密：MD5 Md5Hash md5Hash = new Md5Hash(password); logger.info(md5Hash); //加盐: MD5 + 盐 md5Hash = new Md5Hash(password, "pace2car"); logger.info(md5Hash); //更复杂: MD5 + 盐 + 散列次数 md5Hash = new Md5Hash(password, "pace2car", 3); logger.info(md5Hash); &#125;&#125; 当然对应的Realm也要加上对应的加密方式1234567891011121314151617181920212223242526/** * 认证 * @param token 登录信息包装成的信息 * @return * @throws AuthenticationException */@Overrideprotected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken token) throws AuthenticationException &#123; System.out.println(token); //获取登录的用户名 String username = (String) token.getPrincipal(); //通过用户名到数据库中去查，返回User对象方便比较 //假设已返回数据 if (!"pace2car".equals(username)) &#123; return null; &#125; //模拟数据库中的加密密码 String password = "d2a56c32e5dd87139871d44f99e87a33"; //info对象表示realm登录比对信息+第三个参数为盐 SimpleAuthenticationInfo info = new SimpleAuthenticationInfo(username, password, ByteSource.Util.bytes("chenjiahao"), getName()); return info;&#125; 权限管理在解决登录及加密问题后，就是权限问题了 shiro的权限控制类似于RBAC模型，建议先补充一下预备知识 同样先以ini的方式模拟数据库1234567891011[users]#模拟用户pace2car=123456,role1,role2[roles]#角色role1对user资源拥有create、update权限role1=user:create,user:update#角色role2对user资源拥有create、delete权限role2=user:create,user:delete#角色role3对user资源拥有select权限role3=user:select 测试权限123456789101112131415161718192021222324252627282930@Testpublic void testHasRole() &#123; Factory&lt;SecurityManager&gt; factory = new IniSecurityManagerFactory("classpath:shiro-permission.ini"); SecurityManager securityManager = factory.getInstance(); SecurityUtils.setSecurityManager(securityManager); Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken("pace2car", "123456"); subject.login(token); //用户已登录，这是进行授权的基础 //对角色的检查 //有返回值的检查 logger.info(subject.hasRole("role1")); logger.info(subject.hasAllRoles(Arrays.asList("role1", "role2"))); logger.info(Arrays.toString(subject.hasRoles(Arrays.asList("role1", "role2", "role3")))); //无返回值的检查 subject.checkRole("role1");//继续执行 subject.checkRole("role3");//报错 //对权限的检查 //有返回值的检查 logger.info(subject.isPermitted("user:create")); logger.info(subject.isPermittedAll("user:create", "user:delete")); logger.info(Arrays.toString(subject.isPermitted("user:select", "user:delete"))); //无返回值的检查 subject.checkPermission("user:create");//继续执行 subject.checkPermission("user:select");//报错&#125; 自定义Realm检查权限1234567891011121314151617181920212223/** * 授权 * * @param principals 用户认证信息，认证返回信息中的第一参数：username * @return */@Overrideprotected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principals) &#123; //获取用户凭证 String username = (String) principals.getPrimaryPrincipal(); //模拟查询数据库 List&lt;String&gt; roles = new ArrayList&lt;&gt;(); List&lt;String&gt; permissions = new ArrayList&lt;&gt;(); roles.add("role1"); permissions.add("user:create"); SimpleAuthorizationInfo info = new SimpleAuthorizationInfo(); info.addRoles(roles); info.addStringPermissions(permissions); return info;&#125; 测试代码123456789101112131415@Testpublic void testHasRoleByRealm() &#123; Factory&lt;SecurityManager&gt; factory = new IniSecurityManagerFactory("classpath:shiro-permission-realm.ini"); SecurityManager securityManager = factory.getInstance(); SecurityUtils.setSecurityManager(securityManager); Subject subject = SecurityUtils.getSubject(); UsernamePasswordToken token = new UsernamePasswordToken("chenjiahao", "123456"); subject.login(token); //用户已登录，这是进行授权的基础 logger.info(subject.hasRole("role1")); logger.info(subject.isPermitted("user:create"));&#125; 认识shiroFiltershiro提供类似mvc框架前端请求分发器的Filter，在应用中将这个过滤器配置在分发器之前便可启用shiro的功能 shiro的主要过滤器主要有： 执行流程及优先级： 通过jsp标签的权限控制 Spring整合Shiro引入依赖准备好一个SSM Web项目 添加以下依赖1234567891011121314151617181920212223242526272829303132333435363738394041&lt;!-- shiro --&gt;&lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;commons-collections&lt;/groupId&gt; &lt;artifactId&gt;commons-collections&lt;/artifactId&gt; &lt;version&gt;3.2.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-core&lt;/artifactId&gt; &lt;version&gt;$&#123;shiro.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-web&lt;/artifactId&gt; &lt;version&gt;$&#123;shiro.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;net.sf.ehcache&lt;/groupId&gt; &lt;artifactId&gt;ehcache-core&lt;/artifactId&gt; &lt;version&gt;2.6.11&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-ehcache&lt;/artifactId&gt; &lt;version&gt;$&#123;shiro.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-quartz&lt;/artifactId&gt; &lt;version&gt;$&#123;shiro.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring&lt;/artifactId&gt; &lt;version&gt;$&#123;shiro.version&#125;&lt;/version&gt;&lt;/dependency&gt; 然后引入shiro配置首先是在web.xml中配置shiroFilter12345678&lt;filter&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.DelegatingFilterProxy&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;shiroFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 然后新建一个spring-shiro.xml配置12345678910111213141516171819202122232425262728293031323334&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd &quot;&gt; &lt;!-- 配置自定义的realm 需要自己实现Realm--&gt; &lt;bean id=&quot;userRealm&quot; class=&quot;com.pace2car.shiro.realm.UserRealm&quot; /&gt; &lt;!-- 安全管理器 --&gt; &lt;bean id=&quot;securityManager&quot; class=&quot;org.apache.shiro.web.mgt.DefaultWebSecurityManager&quot;&gt; &lt;property name=&quot;realm&quot; ref=&quot;userRealm&quot;/&gt; &lt;/bean&gt; &lt;!-- shiro真正的过滤器 代理过滤器会从spring容器中去找 --&gt; &lt;bean id=&quot;shiroFilter&quot; class=&quot;org.apache.shiro.spring.web.ShiroFilterFactoryBean&quot;&gt; &lt;property name=&quot;securityManager&quot; ref=&quot;securityManager&quot;/&gt; &lt;property name=&quot;loginUrl&quot; value=&quot;/open/login&quot;/&gt; &lt;property name=&quot;successUrl&quot; value=&quot;/views/index.jsp&quot;/&gt; &lt;property name=&quot;unauthorizedUrl&quot; value=&quot;/404.jsp&quot;/&gt; &lt;property name=&quot;filterChainDefinitions&quot;&gt; &lt;value&gt; &lt;!--静态资源放行--&gt; /static/**=anon /logOut=logout /**=authc &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/beans&gt; 在spring上下文中引用1&lt;import resource=&quot;spring-shiro.xml&quot;/&gt; 启动项目测试访问非登录操作，如果自动跳回配置的登录页面即成功 当然shiro的功能远不止此，更多的学习还是以官方文档为准 参考项目： Spring整合Shiro案例]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>shiro</tag>
        <tag>权限管理</tag>
        <tag>apache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Elasticsearch学习笔记]]></title>
    <url>%2F2018%2F11%2F23%2FElasticsearch%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[基本概念（搬运官方文档）入门Elasticsearch是一个高度可扩展的开源全文搜索和分析引擎。它允许您快速，近实时地存储，搜索和分析大量数据。它通常用作底层引擎/技术，为具有复杂搜索功能和要求的应用程序提供支持。 近实时（NRT）Elasticsearch是一个近实时搜索平台。这意味着从索引文档到可搜索文档的时间有一点延迟（通常是一秒）。 集群集群是一个或多个节点（服务器）的集合，它们共同保存您的整个数据，并提供跨所有节点的联合索引和搜索功能。群集由唯一名称标识，默认情况下为“elasticsearch”。此名称很重要，因为如果节点设置为按名称加入群集，则该节点只能是群集的一部分。 确保不要在不同的环境中重用相同的群集名称，否则最终会导致节点加入错误的群集。例如，您可以使用logging-dev，logging-stage以及logging-prod 用于开发，登台和生产集群。 请注意，如果群集中只有一个节点，那么它是完全正常的。此外，您还可以拥有多个独立的集群，每个集群都有自己唯一的集群名称。 节点节点是作为群集一部分的单个服务器，存储数据并参与群集的索引和搜索功能。就像集群一样，节点由名称标识，默认情况下，该名称是在启动时分配给节点的随机通用唯一标识符（UUID）。如果不需要默认值，可以定义所需的任何节点名称。此名称对于管理目的非常重要，您可以在其中识别网络中哪些服务器与Elasticsearch集群中的哪些节点相对应。 可以将节点配置为按群集名称加入特定群集。默认情况下，每个节点都设置为加入一个名为cluster的集群elasticsearch，这意味着如果您在网络上启动了许多节点并且假设它们可以相互发现 - 它们将自动形成并加入一个名为的集群elasticsearch。 在单个群集中，您可以拥有任意数量的节点。此外，如果您的网络上当前没有其他Elasticsearch节点正在运行，则默认情况下，启动单个节点将形成一个名为的新单节点集群elasticsearch。 索引索引是具有某些类似特征的文档集合。例如，您可以拥有客户数据的索引，产品目录的另一个索引以及订单数据的另一个索引。索引由名称标识（必须全部小写），此名称用于在对其中的文档执行索引，搜索，更新和删除操作时引用索引。 在单个群集中，您可以根据需要定义任意数量的索引。 文档（document）文档是可以编制索引的基本信息单元。例如，您可以为单个客户提供文档，为单个产品提供另一个文档，为单个订单提供另一个文档。该文档以JSON（JavaScript Object Notation）表示，JSON是一种普遍存在的互联网数据交换格式。 在索引/类型中，您可以根据需要存储任意数量的文档。请注意，尽管文档实际上驻留在索引中，但实际上必须将文档编入索引/分配给索引中的类型。 分片和副本索引可能存储大量可能超过单个节点的硬件限制的数据。例如，占用1TB磁盘空间的十亿个文档的单个索引可能不适合单个节点的磁盘，或者可能太慢而无法单独从单个节点提供搜索请求。 为了解决这个问题，Elasticsearch提供了将索引细分为多个称为分片的功能。创建索引时，只需定义所需的分片数即可。每个分片本身都是一个功能齐全且独立的“索引”，可以托管在集群中的任何节点上。 分片很重要，主要有两个原因： 它允许您水平拆分/缩放内容量 它允许您跨分片（可能在多个节点上）分布和并行化操作，从而提高性能/吞吐量分片的分布方式以及如何将其文档聚合回搜索请求的机制完全由Elasticsearch管理，对用户而言是透明的。 在可以随时发生故障的网络/云环境中，非常有用，强烈建议使用故障转移机制，以防分片/节点以某种方式脱机或因任何原因消失。为此，Elasticsearch允许您将索引的分片的一个或多个副本制作成所谓的副本分片或简称副本。 副本很重要，主要有两个原因： 它在分片/节点发生故障时提供高可用性。因此，请务必注意，副本分片永远不会在与从中复制的原始/主分片相同的节点上分配。 它允许您扩展搜索量/吞吐量，因为可以在所有副本上并行执行搜索。总而言之，每个索引可以拆分为多个分片。索引也可以复制为零（表示没有副本）或更多次。复制后，每个索引都将具有主分片（从中复制的原始分片）和副本分片（主分片的副本）。 可以在创建索引时为每个索引定义分片和副本的数量。创建索引后，您还可以随时动态更改副本数。您可以使用_shrink和_splitAPI 更改现有索引的分片数，但这不是一项简单的任务，并且预先计划正确数量的分片是最佳方法。 默认情况下，Elasticsearch中的每个索引都分配了5个主分片和1个副本，这意味着如果群集中至少有两个节点，则索引将包含5个主分片和另外5个副本分片（1个完整副本），总计为每个索引10个分片。 ElasticSearch的安装和配置安装与配置es依赖与jdk，需要java版本8以上的环境 参考这个 启动权限这个是真的坑，首先es默认不允许root启动，而其中bin文件夹又是admin.root所属。。。 解决：先创建一个新用户，将ElasticSearch的安装目录及其子目录改为另外一个非root账户，如：12sudo chown -R esuser elasticsearch-6.5.0sudo chgrp -R esgroup elasticsearch-6.5.0 启动esesuser启动/elasticsearch-6.5.0/bin/elasticsearch,显示started启动成功。 远程访问修改elasticsearch.yml，绑定服务器IP地址。 然后启动es，会发现三个报错，分别是最大文件创建数不够，esuser能够创建的线程数不够，虚拟内存不够1234561.解决第一个错误修改etc/security/下的limits.conf,在文件最后加入esuser soft nofile 65536esuser hard nofile 65536esuser soft nproc 4096esuser hard nproc 4096 1232.解决第二个错误修改etc/security/limits.d/下的20-开头的文件将*改为用户名 12343.解决第三个错误修改etc/下的sysctl.conf文件在最后加上vm.max_map_count=655360执行sysctl -p以生效 解决完后如继续启动失败，重启虚拟机再次尝试 关闭防火墙以方便使用windows客户端访问1234systemctl stop firewalld.service在windows浏览器地址栏键入：http://es服务器ip:9200 安装elasticsearch-head插件安装head插件需要依赖于npm和git，所以应首先安装好两个应用，启动head需要用到grunt，所以也应该安装好grunt 推荐安装cnpm（淘宝的国内镜像）1npm install -g cnpm --registry=https://registry.npm.taobao.org 安装好后123git clone git://github.com/mobz/elasticsearch-head.gitcd elasticsearch-headcnpm install 修改head下的Gruntfile.js12在connect-&gt;server-&gt;optins下添加hostname: &apos;*&apos;, --允许所有IP访问 修改head插件默认的访问地址12进入_site下的app.js修改localhost为es服务器ip地址（在vim命令行模式下使用/搜索localhost） 配置允许es跨域访问1234修改es下config的.yml文件在末尾添加http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot; 打开9100端口(关闭防火墙的忽略)1firewall-cmd --zone=public --add-port=9100/tcp --permanent 重启防火墙1firewall-cmd --reload 具体步骤 启动head在head/node_modules/grunt的bin目录下 grunt server1[root@localhost bin]# ./grunt server 显示12Waiting forever...Started connect web server on http://localhost:9100 则启动成功 关闭防火墙以方便使用windows客户端访问1234systemctl stop firewalld.service在windows浏览器地址栏键入：http://es服务器ip:9100 API学习，用kibana实现增删改查安装kibana下载对应版本的二进制压缩文件，解压缩 修改配置文件，进入config，修改.yml12server.host: &quot;es服务器地址&quot;elasticsearch.url: &quot;http://es服务器地址:9200&quot; 启动kibanaroot启动/kibana/bin/kibana,显示Ready启动成功。1[root@localhost bin]# ./kibana 关闭防火墙以方便使用windows客户端访问1234systemctl stop firewalld.service在windows浏览器地址栏键入：http://kibana服务器ip:5601 在windows连接到kibana后打开Dev Tools开发者工具，在里面键入测试代码：123456GET _search&#123; &quot;query&quot;: &#123; &quot;match_all&quot;: &#123;&#125; &#125;&#125; 然后就可以根据API练习操作了 中文分词器ik安装安装ik需要使用maven，所以事先准备好maven linux下安装maven 解压后，进入目录，用mvn命令安装(安装时间较长)1mvn clean install -Dmaven.test.skip=true 安装完成后，会在target/releases下生成一个.zip包 在es下的plugins创建一个ik文件夹，将zip包复制到ik文件夹中并解压 重启es，会发现plugins中会加载一个ik，就代表安装成功了，后续的使用中就可以在创建索引的时候选择使用ik分词器。 注意：中文分词器ik的版本必须与es版本保持一致（完全一致），一般用master版本编译打包出来的。123版本必须完全一致eg:java.lang.IllegalArgumentException: Plugin [analysis-ik] was built for Elasticsearch version 6.5.0 but version 6.5.1 is running 在创建索引时，自定义mapping，字段属性中加上1&quot;analyzer&quot;: &quot;ik_max_word&quot; 就可以使用中文分词了 在Java应用中使用Elasticsearch创建一个maven项目引入依赖，因为要测试数据操作，所以也要用到junit1234567891011&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;transport&lt;/artifactId&gt; &lt;version&gt;6.5.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 下载完所有依赖后，直接创建测试类 当然测试索引也要事先准备好123456789101112131415161718192021222324252627282930PUT /javademo&#123; &quot;settings&quot;: &#123; &quot;number_of_shards&quot;: 2, &quot;number_of_replicas&quot;: 0 &#125;, &quot;mappings&quot;: &#123; &quot;blog&quot;:&#123; &quot;properties&quot;:&#123; &quot;id&quot;: &#123; &quot;type&quot;: &quot;long&quot; &#125;, &quot;title&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot; &#125;, &quot;content&quot;: &#123; &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;ik_max_word&quot; &#125;, &quot;postdate&quot;: &#123; &quot;type&quot;: &quot;date&quot; &#125;, &quot;url&quot;: &#123; &quot;type&quot;: &quot;text&quot; &#125; &#125; &#125; &#125;&#125; 参考项目： es在Java应用中的测试 es整合spring同样创建maven项目，导入相关依赖12345678910&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch&lt;/artifactId&gt; &lt;version&gt;6.5.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-data-elasticsearch&lt;/artifactId&gt; &lt;version&gt;3.1.3.RELEASE&lt;/version&gt;&lt;/dependency&gt; 创建es配置 applicationContext-elasticsearch.xml:1234567891011121314151617181920212223242526&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:elasticsearch=&quot;http://www.springframework.org/schema/data/elasticsearch&quot; xmlns:context=&quot;http://www.springframework.org/schema/context&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/data/elasticsearch http://www.springframework.org/schema/data/elasticsearch/spring-elasticsearch-1.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd&quot;&gt; &lt;!-- 搜索DAO 扫描 --&gt; &lt;elasticsearch:repositories base-package=&quot;com.pace2car.elastic.dao&quot; /&gt; &lt;!-- 扫描Service包 --&gt; &lt;context:component-scan base-package=&quot;com.pace2car.elastic.service&quot; /&gt; &lt;!-- 配置Client --&gt; &lt;elasticsearch:transport-client id=&quot;client&quot; cluster-name=&quot;my-application&quot; cluster-nodes=&quot;192.168.44.128:9300&quot;/&gt; &lt;!-- 配置搜索模板 --&gt; &lt;bean id=&quot;elasticsearchTemplate&quot; class=&quot;org.springframework.data.elasticsearch.core.ElasticsearchTemplate&quot;&gt; &lt;constructor-arg name=&quot;client&quot; ref=&quot;client&quot; /&gt; &lt;/bean&gt;&lt;/beans&gt; 在spring配置中引入es配置12&lt;!-- 引入 elasticsearch 配置 --&gt; &lt;import resource=&quot;applicationContext-elasticsearch.xml&quot;/&gt; ps：dao层需要继承ElasticsearchRepository,方法名安规范写，框架自动生成查询语句 还有一些注解上的使用，如@Document,@Id,@Field等，具体参考spring-data的官方文档即可 整合完毕收工。 PS：随着es越来越强大，我们甚至可以让它在项目中直接作为持久化存储库（类似于NoSQL），当然，目前大多数的企业开发还是让它作为一个前置搜索引擎来使用，即定时将数据库中的内容同步到es中，在用户进行索引操作时，直接的去从es库中查询，这样也能充分的利用到es近实时的特性（1秒之内）。在更大型的企业中，会利用es来做大数据日志分析的工作，主要技术栈为ELK，大致架构为syslog/logstash/flume -&gt;kafka -&gt;Spark/Track/Storm -&gt;HDFS -&gt;elasticsearch -&gt;kibana]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>elasticsearch</tag>
        <tag>kibana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World!]]></title>
    <url>%2F2018%2F08%2F19%2Fpace2car%2F</url>
    <content type="text"><![CDATA[首先是一个俗套的打招呼方式，hello world！我开始写博客啦！ 这是我的第一篇个人博客，本着交流技术和提高自己的心态，想通过此博客与大家分享学习和成长路程中的心得和曾经踩过的坑，以及程序上小问题。 在两天时间的不懈努力下，跨越各种艰难险阻，各种小坑，终于成功搭建起了自己的博客，一路上感谢各位前人大牛提供的博客援助，这也更加坚定了我写博客的决心和目的——分享经验，给后来人留下一点微不足道的提示和建议。 作者的技术水平十分有限，希望有问题或建议都能够多与作者联系，共同成长！ e-mail: pace2car@163.comauthor: Pace2Car 转载请…算了，反正也不可能有人转载。]]></content>
      <categories>
        <category>杂记</category>
      </categories>
      <tags>
        <tag>起步</tag>
        <tag>HelloWorld!</tag>
      </tags>
  </entry>
</search>
